\documentclass[12pt,class=book,crop=false]{standalone}
\usepackage{../style}
\lstinputpath{../code/}
\graphicspath{ {../img/} }
\begin{document}
\chapter{Root Finding}
\section{Iteration}
Iteration is a numerical method used to find approximation to solutions of equations of the following type, when the exact solution can not be obtained by algebraic methods.\\
Let,\\
\indent \( N_0(t) =\) Initial Population\\
\indent \( N(t) =\) Population at any time\\
\indent \( \lambda =\) Constant birth rate\\
Then we find the differential equations as
\begin{equation}
    \frac{\D}{\D t}\left(N(t)\right)=\lambda N(t) \label{eq:diff}
\end{equation}
Solutions of (\ref{eq:diff}) is
\[
    N(t)=N_0e^{\lambda t}
\]
Suppose immigration is allowed at a constant rate \( V \). Then the differential equation becomes
\begin{equation}
    \frac{\D}{\D t}\left(N(t)\right)=\lambda N(t) +V\label{eq:diffim}
\end{equation}
Solution of (\ref{eq:diffim}) is
\[
    N(t)=N_0e^{\lambda t}+\frac{V}{\lambda}(e^{\lambda t}-1)
\]
If any three are given then the other value can not easily find.
\subsection{Solution of \( f(x)=0 \) by Iteration}
We start with an approximate \( x_0 \) to the solution and apply to it a procedure which gives another approximation \( x_1 \). This new approximation normally a better one, is now used as a new value of \( x_0 \), and the process is repeated.

This iteration is said to converge if we can reach a stage, where \( x_1=x_0 \).
\section{Bisection Method}
\subsection{Bisection Method}
To discuss bisection method we study the following theorem:
\begin{thm}
    Let \( f(x) \) be continuous on \( [a,b] \) and \( f(a) \) and \( f(b) \) are of opposite signs, then there exists at least one \( c\in(a,b) \) such that \( f(c)=0 \). \label{thm:bisec}
\end{thm}

Let \( f(a) \) be negative and \( f(b) \) be positive. Then the root lies between \( a \) and \( b \) and let its approximate value be given by \( x_0=\frac{a+b}{2} \). If \( f(x_0)=0 \), we conclude that \( x_0 \) is a root of the equation \( f(x)=0 \). Otherwise, the root lies either between \( x_0 \) and \( b \) or between \( x_0 \) and \( a \) depending on whether \( f(x_0) \) is negative or positive. Again, choose the second approximation either \( x_1=\frac{a+x_0}{2} \) if \( f(x_0) \) is \( + \)ve or \( x_1=\frac{b+x_0}{2}  \) if \( f(x_0) \) is \( - \)ve. If \( f(x_1)=0 \) then we conclude that \( x_1 \) is the root of \( f(x)=0 \). Otherwise, again choose a new approximation. Repeat the process until the root is known to the desired accuracy. This method is shown graphically in the following figure:
\begin{figure}[H]
    \centering
    \import{../tikz/}{bisection.tikz}
    \caption{Bisection Method}
\end{figure}
\begin{prob}
    Find a real root of the equation
    \[
        f(x)=x^3-x-1=0
    \]
\end{prob}
\begin{soln}
    Here, \( f(1)=-1 \) and \( f(2)=2^3-2-1=5 \)\\
    Thus \( f(1)=-1<0<5=f(2) \)\\
    By the above theorem (\ref{thm:bisec}) \( f(x) \) has at least one root in the interval \( [1,2] \).\\
    Here \( f'(x)=3x-1, f'(1)=2, f'(2)=11 \)
    If \( f(x) \) vanishes at one or more points in the interval \( [1,2] \), then by Rolle's theorem \( f'(x) \) should vanish somewhere in \( [1,2] \).\\

    Since \( f'(x) \) is positive on \( [1,2] \), \( f(x) \) has exactly one root in \( [1,2] \), say \( P \).\\
    \indent Take \( P=\frac{1+2}{2}=1.5 \)\\
    \indent Here \( \abs{\text{error}}\leq 0.5 \)\\
    Evaluate \( f(P)=f(1.5)=0.875>0>-1=f(1) \)\\
    The root lies in the smaller interval \( [1,1.5] \)\\
    Now,
    \indent take \( P_1=\frac{1+1.5}{2}=\frac{2.5}{2}=1.25 \)\\
    \indent Here \( \abs{\text{error}}\leq 0.25 \)\\
    Again,\\
    \indent \( \begin{aligned}
        f(1.25) & =(1.25)^3-1.25-1             \\
                & =-0.296\,875<0<0.875=f(1.25)
    \end{aligned} \)\\
    So the new interval is \( [1.25,1.5] \), i.e.\ the root lies in the smaller interval \( [1.25,1.5] \).\\

    Take the new approximation \( P_2=\frac{1.25+1.5}{2}=1.375 \)\\
    \indent Here \( \abs{\text{error}}\leq 0.125 \)\\
    The procedure is repeated and the successive approximations are \( P_3=1.312\,5 \), \( P_4=1.343\,75 \), \( P_5=1.328\,125 \), etc.\\
    After \( 20 \) times \( 1.324\,171\,75\leq P_{20}\leq 1.324\,471\,85 \)
\end{soln}
\subsection{Definition of Bisection Method}
The process of locating a solution of an equation \( f(x)=0 \) in a sequence of intervals of decreasing size and increasing accuracy is known as the \emph{Bisection method.}

Each step of the above algorithm is of the bisection method produces one more correct digit of the root of \( f(x)=0 \).\\

So one can always locate a root to any desired accuracy with this algorithm. But Bisection method converges to the required accuracy very slowly.

The bisection method calls for a repeated halving of a subintervals \( [a,b] \) and at each step locating the `half' containing the root \( P \).
\subsection{Bisection Method}

Suppose \( f(x) \) is a continuous function defined on \( [a,b] \) with \( f(a) \) and \( f(b) \) of opposite signs.

Then by the theorem (\ref{thm:bisec}) there exists \( P\in[a,b] \) such that \( f(P)=0 \).

\underline{Process:}
\begin{enumerate}
    \item To start, set \( a_1=a \), \( b_1=b \), \( P_1=\frac{a+b}{2} \)
    \item If \( f(P_1)=0 \), then \( P=P_1 \) and the process is complete
    \item If \( f(P_1)\neq 0 \), then \( f(P_1) \) has same sign as either \( f(a_1) \) or \( f(b_1) \)
    \item If \( f(P_1) \) and \( f(a_1) \) have the same sign then \( P\in [P_1,b_1 ] \) and set \( a_2=P_1 \), \( b_2=b_1 \)
    \item If \( f(P_1) \) and \( f(b_1) \) have the same sign then \( P\in [a_1,P_1 ] \) and set \( a_2=a_1 \), \( b_2=P_1 \)
\end{enumerate}
Repeat the process to the new interval \( [a_2,b_2] \)
\subsection{Algorithm For Bisection Method}
\subsubsection{Data Table}
Input Variables:
\begin{align*}
    a,b,N & =\text{no of iterations}      \\
    ERR   & =\text{maximum error allowed} \\
    f(x)  & =0
\end{align*}
Output Variables:
\begin{align*}
    P            & =\text{Approximate solution}                                                   \\
    \text{or, }m & =\text{Number of steps and message showing iteration failed in \( m \) steps.}
\end{align*}
\subsubsection{Algorithm}
\begin{enumerate}[label={Step \arabic* :} ]
    \item Set \( I=1 \) (initialized counter)
    \item If \( I\leq N \), Do steps 3-6
          {\setlength\itemindent{50pt}\item set \( P=a+(b-a)/2.0 \)}
          {\setlength\itemindent{50pt}\item If \( f(P)=0 \) or \( (b-a)/2.0 <\, ERR\), THEN\\
          \-\hspace{1.55cm} Output \( P \)(procedure compiled successfully)\\
          \-\hspace{1.55cm} STOP}
          {\setlength\itemindent{50pt}\item ELSE set \( I=I+1 \)}
          {\setlength\itemindent{50pt}\item If \( f(a)f(P)>0 \) THEN\\
          \-\hspace{1.55cm} set \( a=P \)\\
          \-\hspace{1.55cm} ELSE set \( b=P \)}
    \item Output (Method failed after \( m=N \) iterations,
          procedure computed unsuccessfully)\\
          STOP
\end{enumerate}
\newpage
\subsection{Sample Code}
\lstinputlisting[caption={A sample program to solve \(x^3+x^2+x+7=0\) by using bisection method}]{bisection.f90}
\newpage
\section{Newton-Raphson Method}
\subsection{Newton-Raphson Method}
This is one of most powerful method general application for deriving an iteration formula for the solution of \( f(x)=0 \).
\subsection{Newton-Raphson Formula}
Let,\\
\indent \( x_0= \) Initial approximation of root of \( f(x)=0 \)\\
\indent \( \xi = \) error, \( \xi \) is sufficiently small\\
Now let \( x_1=x_0+\xi  \) then \( f(x_1)=0 \)\\
\indent \( \Rightarrow f(x_0+\xi)=0 \)\\
By Taylors expansion we get,
\[
    f(x_0)+\xi f'(x_0)+\frac{1}{2!}\xi^2 f''(x_0)+\dots=0
\]
Now if \( \xi  \) is sufficiently small, we may neglect the terms containing second and higher powers of \( \xi \) and we get
\[
    f(x_0)+\xi f'(x_0)=0
\]
This gives
\[
    \xi=\frac{f(x_0)}{f'(x_0)}\quad \text{ provided } f'(x_0)\neq 0
\]
A better approximation than \( x_0 \) is therefore given by \( x_1 \) where,
\[
    x_1=x_0-\xi=x_0-\frac{f(x_0)}{f'(x_0)}
\]
Successive approximations are given by \( x_2, x_3,\dots,x_{n+1} \) where
\[
    x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
\]
The above is known as Newton-Raphson formulae.
\subsection{Graphical Interpretation of N-R Formulae}
\begin{figure}[H]
    \centering
    \import{../tikz/}{newton-rap.tikz}
    \caption{Graphical Interpretation of Newton-Raphson Method}
\end{figure}
Geometrically Newton-Raphson method consists in drawing a tangent to the curve \( y=f(x) \) at \( x=x_0 \) and finding the point \( x_1 \), at which the tangent intersects the \( x \)-axis. This leads to,
\[
    \frac{f(x_0-0)}{x_0-x_1}=f'(x_0)
\]
gives the N-R iteration formula,
\[
    x_1=x_0-\frac{f(x_0)}{f'(x_0)}
\]
\begin{note}
    If we need a root accurate to, say \( k \) decimal places, then we have to need
    \[
        \begin{aligned}
            \abs{x_{n+1}-x_n} & <10^{-k}           \\
                              & \downarrow         \\
            \text{error}      & \,\text{tolerance}
        \end{aligned}
    \]
\end{note}
\subsection{Disadvantages of Newton-Raphson Method}
Newton-Raphson method is very good near the root, but has two disadvantages:
\begin{enumerate}
    \item Initial estimate has to be close to the root, so we need a method for good estimate.
    \item Newton-Raphson method required the derivative of \( f(x) \), but this may be difficult.
\end{enumerate}
\subsection{Newton-Raphson's Method Converges Quadratically}
Newton-Raphson's method gives a quadratic-convergence of the result, provided initial approximation is near to the root.

We know from Newton-Raphson formula,
\begin{align}
                & x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}\notag        \\
    \Rightarrow & f(x_n)+(x_{n+1}-x_n)f'(x_n)=0 \label{eq:nrquad}
\end{align}
To find the root of \( f(x)=0 \),
\[\left.{\begin{aligned}
        \text{Suppose, }P & =\text{root} \\
        \therefore P      & =x_n+\xi     \\
                          &              \\
    \end{aligned}}\qquad\right\vert\qquad{\begin{aligned}
            \xi            & = \text{error}            \\
            x_n            & = \text{approximate root} \\
            \therefore \xi & =P-x_n\approx l_n
        \end{aligned}}\]
By Taylor's expansion
\begin{align}%should there be a factorial sign
    0=f(P)      & =f(x_n+\xi)= f(x_n)+\xi f'(x_n)+\frac{1}{2!}\xi^2 f''(x_n)+\dots \label{eq:nrquad2} \\
    \intertext{By subtracting (\ref{eq:nrquad}) from (\ref{eq:nrquad2})}
    \Rightarrow & (\xi-x_{n+1}+x_n)f'(x_n)+\frac{1}{2!}\xi^2 f''(x_n)=0\notag                         \\
    \Rightarrow & (P-x_{n+1})f'(x_n)+\frac{1}{2}\xi^2 f''(x_n)=0\notag
\end{align}
Now,
\[
    P-x_{n+1}=l_{n+1}=\text{ error after }(n+1)\text{ iteration}
\]
Then,
\begin{align*}
                 & l_{n+1}f'(x_n)+\frac{1}{2}\xi^2 f''(x_n)=0                                    \\
    \Rightarrow  & l_{n+1}f'(x_n)+\frac{1}{2}l_n^2 f''(x_n)=0                                    \\
    \Rightarrow  & l_{n+1}=-\frac{1}{2}\frac{f''(x_n)}{f'(x_n)}l_n^2                             \\
    \Rightarrow  & l_{n+1}=k\cdot l_n^2\qquad\text{where }k=-\frac{1}{2}\frac{f''(x_n)}{f'(x_n)} \\
    \text{ie.\ } & l_{n+1}\propto l_n^2
\end{align*}
Hence each error is roughly proportional to the square of the previous error, i.e., the number of correct decimal places roughly doubles with each approximation. Hence, it is said that Newton-Raphson's method converges quadratically to the exact root.
\newpage
\subsection{Sample Code}
\lstinputlisting[caption={A sample program to solve \( x^3-3x+1=0 \) by using Newton-Raphson method}]{newton-raphson.f90}
\newpage
\subsection{Problems}
\begin{prob}
    Using Newton-Raphson's method, find the root of \( x^3-3x=3 \) that lies near \( x=2 \) correct upto \( 4 \)D.
\end{prob}
\begin{soln}
    We know the Newton-Raphson's formula is
    \begin{equation}
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)} \label{eq:prob1.1}
    \end{equation}
    We are given,\\
    \indent \( f(x)=x^3-3x-3=0 \)\\
    \indent \( x_0=2 \)\\
    Now, \( f'(x)=3x^2-3 \)\\
    From (\ref{eq:prob1.1}),
    \begin{align}
        x_{n+1}            & =x_n-\frac{x_n^3-3x_n-3}{3x_n^2-3}\notag         \\
                           & =\frac{3x_n^3-3x_n-x_n^3+3x_n+3}{3x_n^2-3}\notag \\
        \therefore x_{n+1} & =\frac{2x_n^3+3}{3x_n^2-3}\label{eq:prob1.2}
    \end{align}
    From (\ref{eq:prob1.2}), For \( n=0 \),
    \[
        x_1=\frac{2x_0^3+3}{3x_0^2-3}=\frac{2\cdot{2}^3+3}{3\cdot{2}^2-3}=2.111\,11
    \]
    For \( n=1 \),
    \[
        x_2=\frac{2x_1^3+3}{3x_1^2-3}=\frac{2\cdot{2.111\,11}^3+3}{3\cdot{2.111\,11}^2-3}=2.103\,835
    \]
    For \( n=2 \),
    \[
        x_3=\frac{2x_2^3+3}{3x_2^2-3}=\frac{2\cdot{2.103\,835}^3+3}{3\cdot{2.103\,835}^2-3}=2.103\,803\,4
    \]
    So the required root \( x\approx 2.103\,8 \)
\end{soln}
\begin{prob}
    Find a solution to the equation \( x=\cos x \) correct upto \( 10 \)D.
\end{prob}
\begin{soln}
    Here, we are given,\\
    \indent \( f(x)=\cos x-x=0 \)\\
    \indent \( f'(x)=-\sin x-1 \)\\
    Here,
    \begin{align*}
                   & f(0)=1-0=1                                      \\
                   & f(\frac{\pi}{2})=0-\frac{\pi}{2}=-\frac{\pi}{2} \\
        \therefore & f(\frac{\pi}{2})=-\frac{\pi}{2}<0<1=f(0)
    \end{align*}
    So we can choose the interval \( [0,\frac{\pi}{2}] \)
    It is clear that \( f(x) \) is continuous on \( [0,\frac{\pi}{2}]\), so by theorem there exist a root of \( f(x)=0 \) in the interval \( [0,\frac{\pi}{2}]\).\\
    We know,
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    Here,
    \begin{align}
        x_{n+1}            & =x_n-\frac{\cos x_n-x_n}{-\sin x_n -1}\notag                \\
                           & =\frac{x_n\sin x_n+x_n+\cos x_n-x_n}{\sin x_n +1}\notag     \\
        \therefore x_{n+1} & =\frac{x_n\sin x_n+\cos x_n}{\sin x_n +1}\label{eq:prob2.1}
    \end{align}
    Suppose the first approximation is \( x_0=\frac{0+\frac{\pi}{2}}{2}=\frac{\pi}{4} \)\\
    Putting \( n=0,1,2,3,\dots \) in (\ref{eq:prob2.1}) we get,
    \begin{center}
        \begin{tabular}{cc}
            \toprule
            \( n= \) iteration & \( x_n  \) (upto \( 10 \)D) \\\midrule
                               & \(x_0  = 0.785\,398\,163\)  \\
            \( 0 \)            & \(x_1  = 0.739\,536\,133\)  \\
            \( 1 \)            & \(x_2= 0.739\,085\,178  \)  \\
            \( 2 \)            & \(x_3= 0.739\,085\,133  \)  \\
            \( 3 \)            & \(x_4= 0.739\,085\,133  \)  \\\bottomrule
        \end{tabular}
    \end{center}
    So the required root is \( 0.739\,085\,133 \).
\end{soln}
\begin{prob}
    Obtain solution of \( x^3+4x^2-10=0 \) in the interval \( [1,2] \) by Newton-Raphson method correct upto \( 8 \)D.
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x^3+4x^2-10=0 \)\\
    \indent \( f'(x)=3x^2+8x \)\\
    Here \( f(1)=-5,\,f(2)=14 \)\\
    So \( f(1)=-5<0<14=f(2)\)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( [1,2] \).\\
    Suppose, an approximate root is \( x_0=\frac{1+2}{2}=1.5 \)\\
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    Here,
    \begin{align}
        x_{n+1}             & =x_n-\frac{x_n^3+4x_n^2-10}{3x_n^2+8x_n}\notag          \\
        \Rightarrow x_{n+1} & =\frac{2x_n^3+4x_n^2+10}{3x_n^2+8x_n}\label{eq:prob3.1}
    \end{align}
    \newpage
    Putting \( n=0,1,2,3,\dots \) in (\ref{eq:prob3.1}) we get,
    \begin{center}
        \begin{tabular}{cl}
            \toprule
            \( n= \) iteration & \multicolumn{1}{c}{\( x_n  \) (upto \( 8 \)D)} \\\midrule
                               & \( x_0 = 1.5\)                                 \\
            \(0\)              & \( x_1 = 1.373\,333\,333\)                     \\
            \( 1 \)            & \(x_2= 1.365\,262\,015  \)                     \\
            \( 2 \)            & \(x_3= 1.365\,230\,014  \)                     \\
            \( 3 \)            & \( x_4= 1.365\,230\,013 \)                     \\\bottomrule
        \end{tabular}
    \end{center}
    \begin{align*}
        x_1 & =\frac{2x_0^3+4x_0^2+10}{3x_0^2+8x_0}=\frac{2(1.5)^3+4(1.5)^2+10}{3(1.5)^2+8(1.5)}=1.373\,333\,333 \\
        x_2 & =\frac{2x_1^3+4x_1^2+10}{3x_1^2+8x_1}=1.365\,262\,015                                              \\
        x_3 & =\frac{2x_2^3+4x_2^2+10}{3x_2^2+8x_2}=1.365\,230\,014                                              \\
        x_4 & =\frac{2x_3^3+4x_3^2+10}{3x_3^2+8x_3}=1.365\,230\,013
    \end{align*}
    So the required root is \( 1.365\,230\,01 \).\\
\end{soln}
\begin{prob}
    Find the root of \( x^3-3x+1=0 \) by Newton-Raphson Method, correct upto \( 5 \)D.
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x^3-3x+1=0 \)\\
    \indent \( f'(x)=3x^2-3 \)\\
    Here \( f(1)=-1,\,f(2)=8-6+1=3 \)\\
    So \(\therefore f(1)=-1<0<3=f(2)\)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( [1,2] \).\\
    Suppose, an approximate root is \( x_0=\frac{1+2}{2}=1.5 \)\\
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    Here,
    \begin{align}
        x_{n+1}             & =x_n-\frac{x_n^3-3x_n+1}{3x_n^2-3}\notag     \\
        \Rightarrow x_{n+1} & =\frac{2x_n^3-1}{3x_n^2-3}\label{eq:prob4.1}
    \end{align}
    Putting \( n=0,1,2,3,\dots \) in (\ref{eq:prob4.1}) we get,
    \begin{center}
        \begin{tabular}{cl}
            \toprule
            \( n= \) iteration & \multicolumn{1}{c}{\( x_n  \) (upto \( 5 \)D)} \\\midrule
                               & \(x_0 = 1.5\)                                  \\
            \(0\)              & \(x_1  = 1.533\,333\,333\)                     \\
            \( 1 \)            & \(x_2= 1.532\,090\,643   \)                    \\
            \( 2 \)            & \(x_3= 1.532\,088\,886  \)                     \\
            \( 3 \)            & \(x_4= 1.532\,088\,886 \)                      \\\bottomrule
        \end{tabular}
    \end{center}
    So the required root is \( 1.532\,08 \).
    \begin{note}
        Another interval \( [0,1] \)\\
        solution \( 0.347\,29 \)
    \end{note}
\end{soln}
\begin{prob}
    Find the root of \( x-\sin x -1=0 \) by Newton-Raphson method, correct upto \( 5 \)D.
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x-\sin x-1=0 \)\\
    \indent \( f'(x)=1-\cos x \)\\
    \begin{figure}[H]
        \centering
        \import{../tikz/}{prob-1-newton-rap.tikz}
    \end{figure}
    Here \( \begin{aligned}[t]
        f(0)            & =-1              \\
        f(\pi)          & =\pi -1          \\
        \therefore f(0) & =-1<0<\pi=f(\pi)
    \end{aligned}\)\\
    So we can choose the interval \( [0,\pi] \)\\
    Let us consider an approximate root, \( x_0=\frac{0+\pi}{2}=\frac{\pi}{2} \)\\
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    \begin{align*}
        x_{n+1}             & =x_n-\frac{x_n-\sin x_n -1}{1-\cos x_n}      \\
        \Rightarrow x_{n+1} & =\frac{\sin x_n- x_n\cos x_n +1}{1-\cos x_n}
    \end{align*}
    When \( n=0 \)
    \begin{align*}
        x_1 & =\frac{\sin x_0- x_0\cos x_0 +1}{1-\cos x_0}                                         \\
            & =\frac{\sin \frac{\pi}{2}- \frac{\pi}{2}\cos \frac{\pi}{2} +1}{1-\cos \frac{\pi}{2}} \\
            & =2
    \end{align*}
    When \( n=1 \), then
    \[
        x_2=\frac{\sin 2- 2\cos 2 +1}{1-\cos 2}=1.935\,951\,152
    \]
    When \( n=2 \), then
    \[
        x_3=\frac{\sin x_2- x_2\cos x_2 +1}{1-\cos x_2}=1.934\,563\,874
    \]
    When \( n=3 \), then
    \[
        x_4=\frac{\sin x_3- x_3\cos x_3 +1}{1-\cos x_3}=1.934\,563\,211
    \]
    So the required root is \( 1.934\,56 \).
\end{soln}
\begin{prob}
    Find the root of \( e^{-x}=\sin x \) upto \( 5 \)D.
\end{prob}
\begin{soln}
    Here we are given that,\\
    \indent \( f(x)=e^{-x}-\sin x=0 \)
    \begin{figure}[H]
        \begin{minipage}[c]{0.68\textwidth}
            \centering
            \import{../tikz/}{prob-2-newton-rap.tikz}
        \end{minipage}\hfill
        \begin{minipage}[c]{0.28\textwidth}
            \centering
            \begin{tabular}{SS}
                \toprule
                \multicolumn{1}{c}{\( x \)} & \multicolumn{1}{c}{\( e^{-x} \)} \\\midrule
                0                           & 1                                \\
                1                           & 0.36787                          \\
                2                           & 0.13533                          \\
                3                           & 0.04978                          \\
                -1                          & 2.71820                          \\
                -2                          & 7.38900                          \\\bottomrule
            \end{tabular}
        \end{minipage}
    \end{figure}
    % \begin{center}
    %     \begin{tabular}{|c|c|c|c|c|c|c|}
    %         \hline
    %         \( x \)      & \( 0 \) & \( 1 \)       & \( 2 \)       & \( 3 \)       & \( -1 \)     & \( -2 \)     \\\hline
    %         \( e^{-x} \) & \( 1 \) & \( 0.367\,87 \) & \( 0.135\,33 \) & \( 0.049\,78 \) & \( 2.718\,2 \) & \( 7.389\,0 \) \\\hline
    %     \end{tabular}
    % \end{center}
    % \newpage
    \indent\indent \( f(x)=\sin x-e^{-x} \)\\
    \indent \( f'(x)=\cos x+e^{-x} \)\\
    Here, \( \begin{aligned}[t]
        f(0)             & =-1                                                     \\
        f(\frac{\pi}{2}) & =1-e^{-\frac{\pi}{2}}=1-0.207\,879\,576=0.792\,120\,423 \\
        \therefore f(0)  & =-1<0<0.792\,1=f(\frac{\pi}{2})
    \end{aligned} \)\\
    So we can choose the interval \( [0,\frac{\pi}{2}] \)\\
    It is clear that \( f(x) \) is continuous on \( [0,\frac{\pi}{2}] \)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( [0,\frac{\pi}{2}] \).\\
    We take the approximate root \( x_0=\frac{0+\frac{\pi}{2}}{2}=\frac{\pi}{4}=0.785\,398\,163 \)\\
    \newpage
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    \begin{align*}
        x_{n+1}             & =x_n-\frac{\sin x_n-e^{-x_n}}{\cos x_n+e^{-x_n}}                     \\
                            & =\frac{x_n\cos x_n+x_ne^{-x_n}-\sin x_n-e^{-x_n}}{\cos x_n+e^{-x_n}} \\
        \Rightarrow x_{n+1} & =\frac{x_n\cos x_n-\sin x_n+(x_n+1)e^{-x_n}}{\cos x_n+e^{-x_n}}
    \end{align*}
    Put \( n=0 \) then,
    \begin{align*}
        x_{1} & =\frac{x_0\cos x_0-\sin x_0+(x_0+1)e^{-x_0}}{\cos x_0+e^{-x_0}} \\
              & =0.569\,440\,334
    \end{align*}
    Put \( n=1 \) then,
    \begin{align*}
        x_{2} & =\frac{x_1\cos x_1-\sin x_1+(x_1+1)e^{-x_1}}{\cos x_1+e^{-x_1}} \\
              & =0.588\,389\,482
    \end{align*}
    Put \( n=2 \) then,
    \begin{align*}
        x_{3} & =\frac{x_2\cos x_2-\sin x_3+(x_2+1)e^{-x_2}}{\cos x_2+e^{-x_2}} \\
              & =0.588\,532\,735
    \end{align*}
    Put \( n=3 \) then,
    \begin{align*}
        x_{4} & =\frac{x_3\cos x_3-\sin x_3+(x_3+1)e^{-x_3}}{\cos x_3+e^{-x_3}} \\
              & =0.588\,532\,744
    \end{align*}
    So the required root is \( 0.588\,53 \).
\end{soln}
\begin{prob}
    Use Newton-Raphson's method to find approximate solutions of the following (within \( 10^{-5} \)):
    \[f(x)=x^3-2x^2-5=0 \,\text{ in }\,[1,5]\,\text{ with }\,x_0=2.5\]
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x^3-2x^2-5=0 \)\\
    \indent \( f'(x)=3x^2-4x \)\\
    \indent \( f(1)=1-2-5=-6\)\\
    \indent \(f(4)=4^3-2\cdot 4^2-5=27 \)\\
    So \( f(1)=-6<0<27=f(4)\)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( [1,4] \).\\
    Let the approximate solution be \( x_0=2.5 \)
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    In this case,
    \begin{align}
        x_{n+1}             & =x_n-\frac{x_n^3-2x_n^2-5}{3x_n^2-4x_n}\notag           \\
        \Rightarrow x_{n+1} & =\frac{3x_n^3-4x_n^2-x_n^3+2x_n^2+5}{3x_n^2-4x_n}\notag \\
        \Rightarrow x_{n+1} & =\frac{2x_n^3-2x_n^2+5}{3x_n^2-4x_n}\label{eq:prob7.1}
    \end{align}
    Put \( n=0 \) in (\ref{eq:prob7.1}) we get,
    \[
        x_{1} =\frac{2x_0^3-2x_0^2+5}{3x_0^2-4x_0}=2.714\,285\,714
    \]
    Put \( n=1 \) in (\ref{eq:prob7.1}) we get,
    \[
        x_{2} =\frac{2x_1^3-2x_1^2+5}{3x_1^2-4x_1}=2.690\,951\,517
    \]
    Put \( n=2 \) in (\ref{eq:prob7.1}) we get,
    \[
        x_{3} =\frac{2x_2^3-2x_2^2+5}{3x_2^2-4x_2}=2.690\,647\,499
    \]
    Put \( n=3 \) in (\ref{eq:prob7.1}) we get,
    \[
        x_{4} =\frac{2x_3^3-2x_3^2+5}{3x_3^2-4x_3}=2.690\,647\,448
    \]
    So the required root is \( 2.690\,647 \).
\end{soln}
\begin{prob}
    Use Newton-Raphson's method to find approximate solutions of the following (within \( 10^{-5} \)):
    \[f(x)=x-\cos x=0 \,\text{ in }\,\left[0,\frac{\pi}{2}\right]\,\text{ with }\,x_0=0.79\]
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x-\cos x=0 \)\\
    \indent \( f'(x)=1+\sin x\)\\
    Here \( f(0)=-1,\,f\left(\frac{\pi}{2}\right)=1.570\,796\,527 \)\\
    So \(\therefore f(0)=-1<0<1.57=f\left(\frac{\pi}{2}\right)\)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( \left[0,\frac{\pi}{2}\right] \).\\
    We are given the first approximate root \( x_0=0.79 \)\\
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    In this case,
    \begin{align*}
        x_{n+1}             & =x_n-\frac{x_n-\cos x_n}{1+\sin x_n}      \\
        \Rightarrow x_{n+1} & =\frac{x_n \sin x_n+\cos x_n}{1+\sin x_n}
    \end{align*}
    Putting \( n=0,1,2,3,\dots \) we get,
    \begin{center}
        \begin{tabular}{cr@{ = }S[table-format=1.9]}
            \toprule
            \( n= \) iteration & \multicolumn{2}{c}{\( x_n  \) (within \( 10^{-5} \))}               \\\midrule
                               & \(x_0\)                                               & 0.79        \\
            \( 0 \)            & \(x_1\)                                               & 0.73962755  \\
            \( 1 \)            & \(x_2\)                                               & 0.739085198 \\
            \( 2 \)            & \(x_3\)                                               & 0.739085133 \\\bottomrule
        \end{tabular}
    \end{center}
    So the required root is \( 0.739\,085 \).
\end{soln}
\begin{prob}
    Use Newton-Raphson's method to find approximate solutions of the following (within \( 10^{-5} \)):
    \[f(x)=x-0.8-0.2\sin x=0 \,\text{ in }\,\left[0,\frac{\pi}{2}\right]\,\text{ with }\,x_0=0.7854\]
\end{prob}
\begin{soln}
    Here we are given,\\
    \indent \( f(x)=x-0.8-0.2\sin x=0 \)\\
    \indent \( f'(x)=1-0.2\cos x \)\\
    \indent \( f(0)=-0.8\)\\
    \indent \(f\left(\frac{\pi}{2}\right)=\frac{\pi}{2}-0.8-0.2=0.57796326 \)\\
    So \( f(0)=-0.8<0<0.570796326=f\left(\frac{\pi}{2}\right)\)\\
    So by theorem there exist a root of \( f(x)=0 \) in the interval \( \left[0,\frac{\pi}{2}\right] \).\\
    We are given the first approximate solution \( x_0=0.7854 \)\\
    We know, the Newton-Raphson formula is
    \[
        x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}
    \]
    In this case,
    \begin{align}
        x_{n+1}            & =x_n-\frac{x_n-0.8-0.2\sin x_n}{1-0.2\cos x_n}\notag                     \\
                           & =\frac{x_n-0.2x_n\cos x_n-x_n+0.8+0.2\sin x_n}{1-0.2\cos x_n}\notag      \\
        \therefore x_{n+1} & =\frac{0.2\sin x_n-0.2 x_n\cos x_n+0.8}{1-0.2\cos x_n}\label{eq:prob8.1}
    \end{align}
    Put \( n=0 \) in (\ref{eq:prob8.1}) we get,
    \[
        x_{1} =\frac{0.2\sin x_0-0.2 x_0\cos x_0+0.8}{1-0.2\cos x_0}=0.967\,120\,765
    \]
    Put \( n=1 \) in (\ref{eq:prob8.1}) we get,
    \[
        x_{2} =\frac{0.2\sin x_1-0.2 x_1\cos x_1+0.8}{1-0.2\cos x_1}=0.964\,334\,608
    \]
    Put \( n=2 \) in (\ref{eq:prob8.1}) we get,
    \[
        x_{3}=\frac{0.2\sin x_2-0.2 x_2\cos x_2+0.8}{1-0.2\cos x_2}=0.964\,333\,887
    \]
    Put \( n=4 \) in (\ref{eq:prob8.1}) we get,
    \[
        x_{4} =\frac{0.2\sin x_3-0.2 x_3\cos x_3+0.8}{1-0.2\cos x_3}=0.964\,333\,887
    \]
    So the required root is \( 0.964\,333 \).
\end{soln}
% \begin{prob}
%     Use Newton-Raphson's method to find approximate solutions of the following (within \( 10^{-5} \)):
%     \[f(x)=\sin x -\frac{x}{2}=0 \,\text{ in }\,[1,5]\,\text{ with }\,x_0=2.5\]
% \end{prob}
\begin{prob}
    Write down the algorithm for Newton-Raphson method and implement it into Fortran for the function \( f(x)=x_2-e^{-x} \)
\end{prob}
\begin{soln}
    Data Table\\
    Input Variables:
    \begin{align*}
        x_0 & =\text{Initial approximation}        \\
        ERR & =\text{Maximum error allowance}      \\
        N   & =\text{Maximum number of iterations}
    \end{align*}
    Output Variables:
    \begin{align*}
        x & =\text{Approximate solution or message of failure}
    \end{align*}
    Algorithm
    \begin{enumerate}[label={Step \arabic* :} ]
        \item Define function \( f(x) \) and \( f'(x) \)
        \item When \( I\leq N \), Do steps 3-5
              {\setlength\itemindent{50pt}\item set \( x=x_0-\frac{f(x_0)}{f'(x_0)} \)}
              {\setlength\itemindent{50pt}\item If \( \abs{x-x_0}<ERR \), then output \( x \) and message compiled successfully\\
              \-\hspace{1.55cm} STOP}
              {\setlength\itemindent{50pt}\item Otherwise (ELSE)\\
              \-\hspace{1.55cm} set \( x_0=x \)(update value of \( x_0 \))\\
              \-\hspace{1.55cm} CONTINUE}
        \item Output Method failed after \( N \) iterations,\\
              procedure computed unsuccessfully\\
              STOP
    \end{enumerate}
\end{soln}
\end{document}